# -*- coding: utf-8 -*-
"""Model04_MoreEpoch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17zjjd5ajvlEAhn1pdoQBU5glcJSLVdlO
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import pickle
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np
from sklearn.decomposition import PCA
import pandas as pd
import plotly.express as px
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

"""**Data Loading**"""

# === Data Loading ===
# Adjust the file paths as needed.
dataset='/content/drive/MyDrive/Project_Test/New/Dataset/hand_object_data.pkl'
with open(dataset,'rb') as data_file:
    data = pickle.load(data_file)

hand_train, hand_val, hand_test = data['hand_train'], data['hand_val'], data['hand_test']
obj_train, obj_val, obj_test = data['obj_train'], data['obj_val'], data['obj_test']
obj_names_train, obj_names_val, obj_names_test = np.array(data['obj_names'])[data['train_indices']],np.array(data['obj_names'])[data['val_indices']],np.array(data['obj_names'])[data['test_indices']]

batch_size = 64
train_dataset = TensorDataset(torch.tensor(obj_train, dtype=torch.float32),torch.tensor(hand_train, dtype=torch.float32))
val_dataset = TensorDataset(torch.tensor(obj_val, dtype=torch.float32),torch.tensor(hand_val, dtype=torch.float32))
test_dataset = TensorDataset(torch.tensor(obj_test, dtype=torch.float32), torch.tensor(hand_test, dtype=torch.float32))

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size)
test_loader = DataLoader(test_dataset, batch_size=batch_size)

"""**Model**"""

import torch
import torch.nn as nn

class ObjectEncoder(nn.Module):
    def __init__(self, input_dim=7869, hidden_dims=[512, 256], out_dim=128):
        super().__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_dim, hidden_dims[0]),
            nn.BatchNorm1d(hidden_dims[0]),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dims[0], hidden_dims[1]),
            nn.BatchNorm1d(hidden_dims[1]),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dims[1], out_dim)
        )
    def forward(self, x):
        return self.fc(x)

class HandEncoder(nn.Module):
    def __init__(self, input_dim=114, hidden_dim=128, out_dim=64):
        super().__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, out_dim)
        )
    def forward(self, x):
        return self.fc(x)

class PriorNet(nn.Module):
    def __init__(self, cond_dim=128, latent_dim=64):
        super().__init__()
        self.fc_mu = nn.Linear(cond_dim, latent_dim)
        self.fc_logvar = nn.Linear(cond_dim, latent_dim)
    def forward(self, c):
        return self.fc_mu(c), self.fc_logvar(c)

class PosteriorNet(nn.Module):
    def __init__(self, cond_dim=128, hand_dim=64, latent_dim=64):
        super().__init__()
        self.fc_mu = nn.Linear(cond_dim + hand_dim, latent_dim)
        self.fc_logvar = nn.Linear(cond_dim + hand_dim, latent_dim)
    def forward(self, h, c):
        x = torch.cat([h, c], dim=-1)
        return self.fc_mu(x), self.fc_logvar(x)

class Decoder(nn.Module):
    def __init__(self, latent_dim=64, cond_dim=128, hidden_dims=[256, 512], output_dim=114):
        super().__init__()
        self.fc = nn.Sequential(
            nn.Linear(latent_dim + cond_dim, hidden_dims[0]),
            nn.BatchNorm1d(hidden_dims[0]),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dims[0], hidden_dims[1]),
            nn.BatchNorm1d(hidden_dims[1]),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dims[1], output_dim)
        )
    def forward(self, z, c):
        x = torch.cat([z, c], dim=-1)
        return self.fc(x)

class CVAE(nn.Module):
    def __init__(self, latent_dim=64):
        super().__init__()
        self.latent_dim = latent_dim
        self.object_encoder = ObjectEncoder()
        self.hand_encoder = HandEncoder()
        self.prior_net = PriorNet(cond_dim=128, latent_dim=latent_dim)
        self.posterior_net = PosteriorNet(cond_dim=128, hand_dim=64, latent_dim=latent_dim)
        self.decoder = Decoder(latent_dim=latent_dim)
    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    def forward(self, obj, hand):
        c = self.object_encoder(obj)
        h = self.hand_encoder(hand)
        mu_q, logvar_q = self.posterior_net(h, c)
        mu_p, logvar_p = self.prior_net(c)
        z = self.reparameterize(mu_q, logvar_q)
        recon_hand = self.decoder(z, c)
        return recon_hand, mu_q, logvar_q, mu_p, logvar_p

def kl_divergence(mu_q, logvar_q, mu_p, logvar_p):
    var_q = torch.exp(logvar_q)
    var_p = torch.exp(logvar_p)
    kl = 0.5 * torch.sum(logvar_p - logvar_q - 1 + (var_q + (mu_q - mu_p)**2) / var_p, dim=1)
    return torch.mean(kl)

if __name__ == '__main__':
    print('The CVAE 04 is loaded.')

"""**Training Code**"""

# === Model Setup ===
latent_dim = 64  # You can try different values (e.g., 32 or 128)
model = CVAE(latent_dim=latent_dim)

# Use weight decay (e.g., 1e-5) for regularization.
optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)
recon_loss_fn = nn.MSELoss()  # Reconstruction loss

# Learning rate scheduler.
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)

# === Early Stopping Setup ===
best_val_loss = float('inf')
patience = 10
trigger_times = 0

# === Metric Lists Initialization ===
train_losses = []
val_losses = []
val_recon_losses = []
val_pose_errors = []
val_joints_errors = []
val_trans_errors = []

# Define indices for the hand vector (adjust if needed)
hand_pose_dim = 48  # First 48 dims: hand pose
joints_dim = 63     # Next 63 dims: hand joints
trans_dim = 3       # Last 3 dims: hand translation

# --- Extended KL Annealing Schedule ---
def get_beta(epoch, kl_anneal_epochs=20):
    # Increase beta linearly from 0 to 1 over kl_anneal_epochs (longer warmup now)
    return min(1.0, epoch / kl_anneal_epochs)


# === Training Loop ===
def train(model, train_loader, val_loader, epochs=50):
    global best_val_loss, trigger_times
    for epoch in range(1, epochs + 1):
        model.train()
        train_loss_epoch = 0
        beta = get_beta(epoch, kl_anneal_epochs=20)
        print(f"\nEpoch {epoch}: Using beta = {beta:.3f}")

        for obj, hand in tqdm(train_loader, desc=f"Epoch {epoch} Training"):
            optimizer.zero_grad()
            recon_hand, mu_q, logvar_q, mu_p, logvar_p = model(obj, hand)
            recon_loss = recon_loss_fn(recon_hand, hand)
            kl_loss = kl_divergence(mu_q, logvar_q, mu_p, logvar_p)
            loss = recon_loss + beta * kl_loss
            loss.backward()
            optimizer.step()
            train_loss_epoch += loss.item()
        avg_train_loss = train_loss_epoch / len(train_loader)
        train_losses.append(avg_train_loss)

        # === Validation Phase ===
        model.eval()
        val_loss_epoch = 0
        val_recon_loss_epoch = 0
        pose_error_epoch = 0
        joints_error_epoch = 0
        trans_error_epoch = 0

        with torch.no_grad():
            for obj, hand in val_loader:
                recon_hand, mu_q, logvar_q, mu_p, logvar_p = model(obj, hand)
                recon_loss = recon_loss_fn(recon_hand, hand)
                kl_loss = kl_divergence(mu_q, logvar_q, mu_p, logvar_p)
                loss = recon_loss + beta * kl_loss
                val_loss_epoch += loss.item()
                val_recon_loss_epoch += recon_loss.item()

                # Compute detailed errors based on slices of the hand vector.
                pose_err = nn.functional.mse_loss(recon_hand[:, :hand_pose_dim],
                                                  hand[:, :hand_pose_dim],
                                                  reduction='sum')
                joints_err = nn.functional.mse_loss(recon_hand[:, hand_pose_dim:hand_pose_dim+joints_dim],
                                                    hand[:, hand_pose_dim:hand_pose_dim+joints_dim],
                                                    reduction='sum')
                trans_err = nn.functional.mse_loss(recon_hand[:, hand_pose_dim+joints_dim:],
                                                   hand[:, hand_pose_dim+joints_dim:],
                                                   reduction='sum')
                pose_error_epoch += pose_err.item()
                joints_error_epoch += joints_err.item()
                trans_error_epoch += trans_err.item()

        avg_val_loss = val_loss_epoch / len(val_loader)
        avg_val_recon_loss = val_recon_loss_epoch / len(val_loader)
        avg_pose_error = pose_error_epoch / len(val_loader)
        avg_joints_error = joints_error_epoch / len(val_loader)
        avg_trans_error = trans_error_epoch / len(val_loader)

        val_losses.append(avg_val_loss)
        val_recon_losses.append(avg_val_recon_loss)
        val_pose_errors.append(avg_pose_error)
        val_joints_errors.append(avg_joints_error)
        val_trans_errors.append(avg_trans_error)

        print(f"Epoch {epoch}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Recon Loss: {avg_val_recon_loss:.4f}")
        print(f"Pose Error: {avg_pose_error:.4f}, Joints Error: {avg_joints_error:.4f}, Trans Error: {avg_trans_error:.4f}")

        scheduler.step(avg_val_loss)

        # --- Early Stopping Check ---
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            trigger_times = 0
            # Save best model checkpoint.
            torch.save(model.state_dict(), 'best_cvae_hand_pose_v3.pth')
            print("Best model updated.")
        else:
            trigger_times += 1
            if trigger_times >= patience:
                print(f"Early stopping triggered after {epoch} epochs.")
                break

"""**Run Training and Save its Weight and Errors**"""

# Run training
train(model, train_loader, val_loader, epochs=100)

saved_model_path = '/content/drive/MyDrive/Project_Test/New/Training/Model_04/cvae_hand_pose_4_64d.pth'
saved_error_path = '/content/drive/MyDrive/Project_Test/New/Training/Model_04/cvae_losses_errors_4_64d.pkl'

# Save the model
torch.save(model.state_dict(), saved_model_path)
print(f"Model saved to {saved_model_path}")


losses_errors = {
    'train_losses': train_losses,
    'val_losses': val_losses,
    'val_recon_losses': val_recon_losses,
    'val_pose_errors': val_pose_errors,
    'val_joints_errors': val_joints_errors,
    'val_trans_errors': val_trans_errors
}

with open(saved_error_path, 'wb') as f:
    pickle.dump(losses_errors, f)
print("Metrics saved successfully!")

"""**Load Loss and Errors And Plot**"""

saved_error_path = '/content/drive/MyDrive/Project_Test/New/Training/Model_04/cvae_losses_errors_4_64d.pkl'
with open(saved_error_path, 'rb') as errors:
  e = pickle.load(errors)


train_losses,val_losses,val_recon_losses = e['train_losses'],e['val_losses'],e['val_recon_losses']
val_pose_errors,val_joints_errors,val_trans_errors = e['val_pose_errors'],e['val_joints_errors'],e['val_trans_errors']

# === Plotting the Metrics ===
plt.figure(figsize=(12, 8))

plt.subplot(2, 3, 1)
plt.plot(train_losses, label='Train Loss (MSE in mm²)')
plt.title('Train Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss (mm²)')

plt.subplot(2, 3, 2)
plt.plot(val_losses, label='Val Loss', color='orange')
plt.title('Validation Loss (MSE in mm²)')
plt.xlabel('Epoch')
plt.ylabel('Loss (mm²)')

plt.subplot(2, 3, 3)
plt.plot(val_recon_losses, label='Recon Loss', color='green')
plt.title('Validation Reconstruction Loss (MSE in mm²)')
plt.xlabel('Epoch')
plt.ylabel('Loss (mm²)')

# plt.subplot(2, 3, 4)
# plt.plot(val_pose_errors, label='Pose Error', color='red')
# plt.title('Validation Pose Error')
# plt.xlabel('Epoch')
# plt.ylabel('Error')

# plt.subplot(2, 3, 5)
# plt.plot(val_joints_errors, label='Joints Error', color='purple')
# plt.title('Validation Joints Error')
# plt.xlabel('Epoch')
# plt.ylabel('Error')

# plt.subplot(2, 3, 6)
# plt.plot(val_trans_errors, label='Trans Error', color='brown')
# plt.title('Validation Translation Error')
# plt.xlabel('Epoch')
# plt.ylabel('Error')

plt.tight_layout()
plt.show()

"""**Compute Latent Space and PCA**"""

def compute_latent(model, data_loader, model_weight):
    model.load_state_dict(torch.load(model_weight))
    model.eval()
    latent_list = []
    with torch.no_grad():
        for obj, hand in data_loader:
            # obj = obj.view(-1, 2623, 3)

            c = model.object_encoder(obj)
            h = model.hand_encoder(hand)
            # Use the posterior mean as the latent representation.
            mu_q, _ = model.posterior_net(h, c)
            latent_list.append(mu_q.cpu().numpy())
    latent_all = np.concatenate(latent_list, axis=0)
    return latent_all

saved_model_path = '/content/drive/MyDrive/Project_Test/New/Training/Model_04/cvae_hand_pose_4.pth'
latent_dim = 32  # You can try different values (e.g., 32 or 128)
model = CVAE(latent_dim=latent_dim)

latent_vectors = compute_latent(model, test_loader,saved_model_path)

# Perform PCA on latent space
pca = PCA(n_components=latent_vectors.shape[1])  # Keep all components
pca_results = pca.fit_transform(latent_vectors)

plt.figure(figsize=(8, 5))
plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o', linestyle='--')
plt.xlabel("Number of Principal Components")
plt.ylabel("Cumulative Explained Variance")
plt.title("PCA Explained Variance Ratio")
plt.grid(True)
plt.show()

explained_variance = pca.explained_variance_ratio_

# Print cumulative explained variance
cumulative_variance = np.cumsum(explained_variance)
for i, var in enumerate(cumulative_variance):
    print(f"First {i+1} components explain {var:.2%} of the variance")

for i, var in enumerate(explained_variance):
    print(f"Principal Component {i+1} explains {var:.2%} of the variance")

# Plot explained variance ratio
plt.figure(figsize=(20, 5))
plt.bar(range(1, 33), explained_variance, tick_label=[f'PC{i}' for i in range(1, 33)])
plt.xlabel("Principal Component")
plt.ylabel("Explained Variance Ratio")
plt.title("Explained Variance of Each Principal Component")
plt.show()

def plot_2Dpca(pca_results,object_name, x,y):
    pca_df = pd.DataFrame(pca_results[:, :], columns=[f'PC{i+1}' for i in range(pca_results.shape[1])])
    pca_df['Object Name'] = object_name  # Add object names for grouping

    # print(pca_df)

    # Unique object names for plotting
    unique_objects = np.unique(obj_names_test)

    # Plot PCA results for each object
    plt.figure(figsize=(12, 8))
    for obj_name in unique_objects:
        # if obj_name=='035_power_drill'or obj_name=='003_cracker_box':

        subset = pca_df[pca_df['Object Name'] == obj_name]
        plt.scatter(subset[f'PC{x}'], subset[f'PC{y}'], label=obj_name, alpha=0.6)

    # Add plot legend and labels
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title="Object Names")
    plt.xlabel(f"Principal Component {x}")
    plt.ylabel(f"Principal Component {y}")
    plt.title("PCA of Latent Space Grouped by Object Names")
    plt.tight_layout()
    plt.show()

def plot_3Dpca(pca_results,object_name, x,y,z):
    # Assuming 'pca_results' and 'object_names' are already defined
    pca_df = pd.DataFrame(pca_results[:, :], columns=[f'PC{i+1}' for i in range(pca_results.shape[1])])
    pca_df['Object Name'] = object_name  # Add object names for grouping


    # Create a 3D scatter plot with Plotly Express
    fig = px.scatter_3d(
        pca_df,
        x=f'PC{x}',
        y=f'PC{y}',
        z=f'PC{z}',
        color='Object Name',  # Different colors by object name
        hover_name='Object Name',  # Show object name on hover
        title="3D PCA of Latent Space Grouped by Object Names"
    )

    # Update axis labels
    fig.update_layout(height=1000,
                      scene=dict(
                          xaxis_title=f'Principal Component {x}',
                          yaxis_title=f'Principal Component {y}',
                          zaxis_title=f'Principal Component {z}'
                      )
                      )

    fig.show()

# Create a DataFrame for visualization
pca_df = pd.DataFrame(pca_results, columns=[f'PC{i+1}' for i in range(pca_results.shape[1])])

# Display the PCA results table
from IPython.display import display
display(pca_df)

pca_df['Object Name'] = obj_names_test

# Pairwise scatter plot grouped by object names
sns.pairplot(pca_df, hue='Object Name', vars=[f'PC{i+1}' for i in range(32)])
plt.show()

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

def plot_3Dpca_centroid(pca_results, object_names, x, y, z):
    """
    Plots a 3D scatter plot of PCA results grouped by object names and overlays centroids
    for each group.

    Parameters:
    - pca_results: numpy array or similar structure with PCA data.
    - object_names: list-like of names corresponding to each PCA observation.
    - x, y, z: integers indicating which principal components to plot on the respective axes.
    """
    # Create a DataFrame from the PCA results
    pca_df = pd.DataFrame(pca_results, columns=[f'PC{i+1}' for i in range(pca_results.shape[1])])
    pca_df['Object Name'] = object_names  # Add object names for grouping

    # Calculate the centroid of each cluster for the selected principal components
    centroid_df = pca_df.groupby("Object Name")[[f'PC{x}', f'PC{y}', f'PC{z}']].mean().reset_index()

    ###
    # Number of latent dimensions (from the PCA results shape)
    latent_dim = pca_results.shape[1]

    # Prepare an array to hold full PCA coordinates for inverse transform.
    # Initialize with zeros.
    centroids_full_pca = np.zeros((centroid_df.shape[0], latent_dim))

    # Place the 3D centroid values into the appropriate positions.
    # Note: If x, y, z are 1-indexed, then subtract 1 for zero-indexed positions.
    centroids_full_pca[:, [x-1, y-1, z-1]] = centroid_df[[f'PC{x}', f'PC{y}', f'PC{z}']].values

    # Invert the PCA transformation to get latent centroids.
    latent_centroids_projected = pca.inverse_transform(centroids_full_pca)
    ###

    # Print the centroid values for each cluster
    print("Centroids of each cluster:")
    print(centroid_df)

    # Create the 3D scatter plot for all data points using Plotly Express
    fig = px.scatter_3d(
        pca_df,
        x=f'PC{x}',
        y=f'PC{y}',
        z=f'PC{z}',
        color='Object Name',          # Group by object names with distinct colors
        hover_name='Object Name',     # Show the object name when hovering over a point
        title="3D PCA of Latent Space Grouped by Object Names"
    )

    # Add centroids to the plot using a Scatter3d trace from graph_objects
    fig.add_trace(
        go.Scatter3d(
            x=centroid_df[f'PC{x}'],
            y=centroid_df[f'PC{y}'],
            z=centroid_df[f'PC{z}'],
            mode='markers+text',        # Show markers along with text labels
            marker=dict(
                symbol='x',             # Use 'x' markers for centroids
                size=10,                # Size of the centroid markers
                color='black'           # Use black color for contrast
            ),
            text=centroid_df['Object Name'],  # Label each centroid with the object name
            name="Centroids"          # Legend label for centroids
        )
    )

    # Customize the layout and axis labels
    fig.update_layout(
        height=1000,
        scene=dict(
            xaxis_title=f'Principal Component {x}',
            yaxis_title=f'Principal Component {y}',
            zaxis_title=f'Principal Component {z}'
        )
    )

    # Display the plot
    fig.show()
    return centroid_df, latent_centroids_projected

plot_2Dpca(pca_results,obj_names_test, 7,8)

centroid_df,latent_temp=plot_3Dpca_centroid(pca_results,obj_names_test, 7,8,9)

centroid_df['Object Name'][0]

latent_temp[0]

# prompt: as you see in the 3d plot above its clustered by object names? how can I get the centroid of each cluster based on the 3d plot grouped by object names?

import pandas as pd
import numpy as np

def get_centroids(pca_results, object_names):
  """
  Calculates the centroid of each cluster in a 3D PCA plot, grouped by object names.

  Args:
    pca_results: A NumPy array of shape (n_samples, n_components) representing the PCA results.
    object_names: A NumPy array of shape (n_samples,) containing the object names corresponding to each sample.

  Returns:
    A pandas DataFrame where each row represents a centroid, with columns for 'Object Name', 'PC1', 'PC2', and 'PC3'.
    Returns an empty DataFrame if input arrays are empty or have mismatched shapes.
  """

  if not pca_results.size or not object_names.size:
    return pd.DataFrame()

  if pca_results.shape[0] != object_names.shape[0]:
    print("Error: pca_results and object_names must have the same number of samples.")
    return pd.DataFrame()

  pca_df = pd.DataFrame(pca_results[:, :3], columns=['PC1', 'PC2', 'PC3'])
  pca_df['Object Name'] = object_names

  centroids = pca_df.groupby('Object Name').mean()
  return centroids

# Example usage (assuming pca_results and obj_names_test are defined as in your code):
centroids_df = get_centroids(pca_results, obj_names_test)
centroids_df



plot_3Dpca(pca_results,obj_names_test, 1,2,3)
plot_3Dpca(pca_results,obj_names_test, 2,3,4)
plot_3Dpca(pca_results,obj_names_test, 3,4,5)
plot_3Dpca(pca_results,obj_names_test, 4,5,6)
plot_3Dpca(pca_results,obj_names_test, 5,6,7)
plot_3Dpca(pca_results,obj_names_test, 6,7,8)
plot_3Dpca(pca_results,obj_names_test, 7,8,9)
plot_3Dpca(pca_results,obj_names_test, 8,9,10)

"""Elbow Method"""

# Elbow Method
inertia = []

for k in tqdm(range(1, 25)):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(pca_results)
    inertia.append(kmeans.inertia_)


plt.figure(figsize=(8, 6))
plt.plot(range(1, 25), inertia, marker='o')
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.axvline(x=4, color='gray', linestyle='--', alpha=0.5)
plt.savefig('1.jpg')
plt.show()

# Silhouette
sil_scores = []

for k in tqdm(range(2, 25)):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(pca_results)
    score = silhouette_score(pca_results, kmeans.labels_)
    sil_scores.append(score)

plt.figure(figsize=(8, 6))
plt.plot(range(2, 25), sil_scores, marker='o')
plt.title('Silhouette Score for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Silhouette Score')
plt.axvline(x=7, color='gray', linestyle='--', alpha=0.5)
plt.axvline(x=16, color='gray', linestyle='--', alpha=0.5)
plt.savefig("2.jpg")
plt.show()

import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
import plotly.express as px
from scipy.spatial.distance import cdist  # For computing distances

# --- K-Means on PCA results ---
num_clusters = 7
kmeans = KMeans(n_clusters=num_clusters, random_state=42)
clusters = kmeans.fit_predict(pca_results)  # pca_results is your NxM array
centroids = kmeans.cluster_centers_

# Print the centroid coordinates
print("Centroids of K-Means clusters:")
print(centroids)

# --- Create DataFrame for the data points (using first 3 PCs) ---
df_data = pd.DataFrame(pca_results[:, :3], columns=['PC1', 'PC2', 'PC3'])
df_data['Object Name'] = obj_names_test
df_data['Cluster'] = clusters
df_data['Type'] = 'Data'  # Mark as data points

# --- Create DataFrame for the centroids (using first 3 PCs) ---
df_centroids = pd.DataFrame(centroids[:, :3], columns=['PC1', 'PC2', 'PC3'])
df_centroids['Cluster'] = range(num_clusters)
df_centroids['Type'] = 'Centroid'  # Mark as centroids

# --- Determine a label for each centroid ---
# For each cluster, select the object name of the data point that is closest to the centroid.
centroid_labels = []
for i in range(num_clusters):
    # Filter data points belonging to cluster i
    cluster_data = df_data[df_data['Cluster'] == i]
    if not cluster_data.empty:
        # Extract the coordinates of these points
        points = cluster_data[['PC1', 'PC2', 'PC3']].values
        # Reshape the centroid into the proper shape for distance calculation
        centroid_point = centroids[i, :3].reshape(1, -1)
        # Compute Euclidean distances from all points in the cluster to the centroid
        distances = cdist(points, centroid_point, metric='euclidean')
        # Get the index of the nearest data point
        min_index = np.argmin(distances)
        # Retrieve the corresponding object name
        nearest_name = cluster_data.iloc[min_index]['Object Name']
        print(f'Centroid{i+1} , Object Name={nearest_name}')
    else:
        nearest_name = ""
    centroid_labels.append(nearest_name)

# Add the representative object name to the centroids DataFrame
df_centroids['Object Name'] = centroid_labels

# --- Combine data and centroid rows into one DataFrame ---
df_combined = pd.concat([df_data, df_centroids], ignore_index=True)

# Create a column for text labels: show the object name only for centroids
df_combined['Label'] = df_combined.apply(lambda row: row['Object Name'] if row['Type'] == 'Centroid' else "", axis=1)

# Optional: Adjust marker size so centroids appear larger
df_combined['Size'] = df_combined['Type'].apply(lambda x: 15 if x == 'Centroid' else 5)

# --- Create 3D scatter plot with Plotly Express ---
fig = px.scatter_3d(
    df_combined,
    x='PC1',
    y='PC2',
    z='PC3',
    color='Cluster',                           # Color points by cluster
    symbol='Type',                             # Different symbol for data vs. centroid
    size='Size',                               # Centroids appear larger
    text='Label',                              # Display the labels (object names) for centroids
    title="3D PCA of Latent Space with K-Means Clusters and Centroids",
    color_discrete_sequence=px.colors.qualitative.Set1
)

# Optional: Adjust text position if needed
fig.update_traces(textposition='top center')

# Update axes labels in 3D
fig.update_layout(
    scene=dict(
        xaxis_title='Principal Component 1',
        yaxis_title='Principal Component 2',
        zaxis_title='Principal Component 3'
    )
)

fig.show()

import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
import plotly.express as px

# --- K-Means on PCA results ---
num_clusters = 7
kmeans = KMeans(n_clusters=num_clusters, random_state=42)
clusters = kmeans.fit_predict(pca_results)  # pca_results is your NxM array
centroids = kmeans.cluster_centers_

# Print the centroid coordinates
print("Centroids of K-Means clusters:")
print(centroids)

# --- Create DataFrame for the data points (3 PCs) ---
df_data = pd.DataFrame(pca_results[:, :3], columns=['PC1', 'PC2', 'PC3'])
df_data['Cluster'] = clusters
df_data['Type'] = 'Data'  # Mark as data points

# --- Create DataFrame for the centroids (3 PCs) ---
df_centroids = pd.DataFrame(centroids[:, :3], columns=['PC1', 'PC2', 'PC3'])
df_centroids['Cluster'] = range(num_clusters)
df_centroids['Type'] = 'Centroid'  # Mark as centroids

# Combine data and centroid rows
df_combined = pd.concat([df_data, df_centroids], ignore_index=True)

# Optional: Make centroids appear larger in the plot
df_combined['Size'] = df_combined['Type'].apply(lambda x: 15 if x == 'Centroid' else 5)

# --- Create 3D scatter plot with Plotly Express ---
fig = px.scatter_3d(
    df_combined,
    x='PC1',
    y='PC2',
    z='PC3',
    color='Cluster',                           # Color points by cluster
    symbol='Type',                             # Different symbol for data vs. centroid
    size='Size',                               # Centroids appear larger
    title="3D PCA of Latent Space with K-Means Clusters and Centroids",
    color_discrete_sequence=px.colors.qualitative.Set1  # Matches Matplotlib "Set1"
)

# Update axes labels in 3D
fig.update_layout(
    scene=dict(
        xaxis_title='Principal Component 1',
        yaxis_title='Principal Component 2',
        zaxis_title='Principal Component 3'
    )
)

fig.show()

"""**2D T-SNE**"""

tsne = TSNE(n_components=2, random_state=42, perplexity=30)
latent_2d = tsne.fit_transform(latent_vectors)

# Elbow Method
inertia = []

for k in tqdm(range(1, 25)):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(latent_2d)
    inertia.append(kmeans.inertia_)


plt.figure(figsize=(8, 6))
plt.plot(range(1, 25), inertia, marker='o')
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.axvline(x=4, color='gray', linestyle='--', alpha=0.5)
plt.savefig('1.jpg')
plt.show()

# Silhouette
sil_scores = []

for k in tqdm(range(2, 25)):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(latent_2d)
    score = silhouette_score(latent_2d, kmeans.labels_)
    sil_scores.append(score)

plt.figure(figsize=(8, 6))
plt.plot(range(2, 25), sil_scores, marker='o')
plt.title('Silhouette Score for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Silhouette Score')
plt.axvline(x=7, color='gray', linestyle='--', alpha=0.5)
plt.axvline(x=16, color='gray', linestyle='--', alpha=0.5)
plt.savefig("2.jpg")
plt.show()

fig, axes = plt.subplots(2, 2, figsize=(18, 14))
axes = axes.ravel()

for i, k in enumerate([3, 4, 7, 16]):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(latent_2d)

    ax = axes[i]
    ax.scatter(latent_2d[:, 0], latent_2d[:, 1], c=kmeans.labels_, cmap='viridis', s=10)
    ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],
               s=200, c='red', marker='.', label='Centroids')
    ax.set_title(f'KMeans with k = {k}')
    ax.legend()

plt.tight_layout()
plt.savefig('3.jpg')
plt.show()

tsne = TSNE(n_components=3, random_state=42, perplexity=30)
latent_3d = tsne.fit_transform(latent_vectors)

inertia = []

for k in tqdm(range(1, 25)):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(latent_3d)
    inertia.append(kmeans.inertia_)

plt.figure(figsize=(8, 6))
plt.plot(range(1, 25), inertia, marker='o')
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.axvline(x=4, color='gray', linestyle='--', alpha=0.5)
plt.savefig('1.jpg')
plt.show()

# Silhouette
sil_scores = []

for k in tqdm(range(2, 25)):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(latent_3d)
    score = silhouette_score(latent_3d, kmeans.labels_)
    sil_scores.append(score)

plt.figure(figsize=(8, 6))
plt.plot(range(2, 25), sil_scores, marker='o')
plt.title('Silhouette Score for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Silhouette Score')
plt.axvline(x=7, color='gray', linestyle='--', alpha=0.5)
plt.axvline(x=14, color='gray', linestyle='--', alpha=0.5)
plt.savefig("2.jpg")
plt.show()

colors = px.colors.qualitative.Set3

kmeans = KMeans(n_clusters=7, random_state=42)
kmeans.fit(latent_3d)

df = pd.DataFrame(latent_3d, columns=['Component 1', 'Component 2', 'Component 3'])
df['Cluster'] = kmeans.labels_

fig = px.scatter_3d(df, x='Component 1', y='Component 2', z='Component 3', color='Cluster',
                    title=f'KMeans Clusters with k = 7', labels={'Cluster': 'Cluster'},
                    opacity=1, color_continuous_scale=colors)


centroids = kmeans.cluster_centers_
fig.add_scatter3d(x=centroids[:, 0], y=centroids[:, 1], z=centroids[:, 2], mode='markers',
                  marker=dict(color='red', size=5, symbol='x', line=dict(color='black', width=1)),
                  name='Centroids')

fig.update_layout(height = 1200, coloraxis_showscale=False)

centroids[0]

from sklearn.manifold import TSNE

# Suppose you have a numpy array of your latents: latents.shape = (N, latent_dim)
tsne = TSNE(n_components=2, perplexity=30, learning_rate='auto', init='random')
latents_2d = tsne.fit_transform(latent_vectors)

plt.figure(figsize=(10, 6))
for obj_name in np.unique(obj_names_test):
    indices = obj_names_test == obj_name
    plt.scatter(latents_2d[indices, 0], latents_2d[indices, 1], label=obj_name, alpha=0.6)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title="Object Names")
plt.xlabel("t-SNE Dimension 1")
plt.ylabel("t-SNE Dimension 2")
plt.title("t-SNE of Latent Space by Object Names")
plt.tight_layout()
plt.show()

"""3D T-SNE"""

from sklearn.manifold import TSNE

tsne = TSNE(n_components=3, perplexity=30, learning_rate='auto', init='random')
tsne_results = tsne.fit_transform(latent_vectors)

# Plot t-SNE results based on object colored
plt.figure(figsize=(10, 6))
for obj_name in np.unique(obj_names_test):
    indices = obj_names_test == obj_name
    plt.scatter(tsne_results[indices, 0], tsne_results[indices, 1], label=obj_name, alpha=0.6)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title="Object Names")
plt.xlabel("t-SNE Dimension 1")
plt.ylabel("t-SNE Dimension 2")
plt.title("t-SNE of Latent Space by Object Names")
plt.tight_layout()
plt.show()

import plotly.express as px
import pandas as pd
import numpy as np

# Assume tsne_results is a (n_samples, 3) NumPy array and object_names is a (n_samples,) array
# Create a DataFrame for easier plotting with Plotly
df = pd.DataFrame({
    'TSNE-1': tsne_results[:, 0],
    'TSNE-2': tsne_results[:, 1],
    'TSNE-3': tsne_results[:, 2],
    'Object': obj_names_test
})

# Create 3D scatter plot
fig = px.scatter_3d(
    df,
    x='TSNE-1',
    y='TSNE-2',
    z='TSNE-3',
    color='Object',
    opacity=1,
    title="3D t-SNE of Latent Space by Object Names"
)

fig.update_layout(legend_title_text='Object Names')
fig.show()